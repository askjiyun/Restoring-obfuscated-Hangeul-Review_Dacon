{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5acb0c5-02b3-48cb-92c6-68b57d1a38fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754416a3-60d5-40d3-84e0-8563287ea33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"../data/train.csv\"\n",
    "train_df = pd.read_csv(train_path)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d38fc3c-bca8-4045-b0d4-88ab81460d8f",
   "metadata": {},
   "source": [
    "- 모델의 System Input으로 \"복원: {난독화된 리뷰}\" 형식으로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a471cdf7-b39a-4232-a2a5-1c77126b4d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataframe, max_input_length=128, max_target_length=128):\n",
    "    dataframe = dataframe.copy()\n",
    "    dataframe['input_text'] = dataframe['input'].apply(lambda x: f\"복원: {x}\")\n",
    "    dataframe['target_text'] = dataframe['output']\n",
    "    dataframe = dataframe[['input_text', 'target_text']]\n",
    "    return dataframe\n",
    "\n",
    "# Preprocess the training data\n",
    "preprocessed_train_df = preprocess_data(train_df)\n",
    "print(preprocessed_train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d694f32e-ecde-4a01-abe6-176ffccf4a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 데이터 로드\n",
    "train_df = pd.read_csv('../data/train.csv', encoding='utf-8-sig')\n",
    "print(\"Train data shape:\", train_df.shape)\n",
    "print(\"\\nSample data:\")\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9374488-9f7a-46fa-9d22-99ba7915bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 토크나이저 로드 및 분석\n",
    "def analyze_tokenizer(tokenizer, sample_texts):\n",
    "    \"\"\"토크나이저 분석 함수\"\"\"\n",
    "    print(f\"Tokenizer 기본 정보:\")\n",
    "    print(f\"Vocab size: {tokenizer.vocab_size}\")\n",
    "    print(f\"Model max length: {tokenizer.model_max_length}\")\n",
    "    print(f\"PAD token: {tokenizer.pad_token}, {tokenizer.pad_token_id}\")\n",
    "    print(f\"EOS token: {tokenizer.eos_token}, {tokenizer.eos_token_id}\")\n",
    "    print(f\"BOS token: {tokenizer.bos_token}, {tokenizer.bos_token_id}\")\n",
    "    \n",
    "    print(\"\\n샘플 텍스트 토큰화 예시:\")\n",
    "    for text in sample_texts:\n",
    "        tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        decoded = tokenizer.convert_ids_to_tokens(tokens['input_ids'][0])\n",
    "        print(f\"\\n입력 텍스트: {text}\")\n",
    "        print(f\"토큰화 결과: {decoded}\")\n",
    "        print(f\"토큰 수: {len(decoded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a34b27-7b2c-44d9-9f9a-8aa8af8b26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 텍스트로 토크나이저 분석\n",
    "sample_texts = [\n",
    "    train_data['input_text'].iloc[0],\n",
    "    train_data['target_text'].iloc[0]\n",
    "]\n",
    "analyze_tokenizer(tokenizer, sample_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc372e-3081-426d-a6d8-6046cf9bd326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 토큰 길이 계산 함수\n",
    "def calculate_token_lengths(texts, tokenizer):\n",
    "    token_lengths = [len(tokenizer(text, truncation=False)['input_ids']) for text in texts]\n",
    "    return token_lengths\n",
    "\n",
    "# 입력 텍스트와 타겟 텍스트 길이 계산\n",
    "input_lengths = calculate_token_lengths(preprocessed_train_df['input_text'], tokenizer)\n",
    "target_lengths = calculate_token_lengths(preprocessed_train_df['target_text'], tokenizer)\n",
    "\n",
    "# 길이 분포 시각화\n",
    "plt.hist(input_lengths, bins=50, alpha=0.6, label='Input Text Lengths')\n",
    "plt.hist(target_lengths, bins=50, alpha=0.6, label='Target Text Lengths')\n",
    "plt.axvline(x=int(pd.Series(input_lengths).quantile(0.99)), color='blue', linestyle='--', label='95% Input')\n",
    "plt.axvline(x=int(pd.Series(target_lengths).quantile(0.99)), color='orange', linestyle='--', label='95% Target')\n",
    "plt.xlabel('Token Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Token Length Distribution')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e9626a-f1a6-433f-bfc1-982f32969614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 95% 커버 기준 max_length 설정\n",
    "input_max_length = int(pd.Series(input_lengths).quantile(0.99))\n",
    "target_max_length = int(pd.Series(target_lengths).quantile(0.99))\n",
    "print(f\"99% 기준 Input Max Length: {input_max_length}\")\n",
    "print(f\"99% 기준 Target Max Length: {target_max_length}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
